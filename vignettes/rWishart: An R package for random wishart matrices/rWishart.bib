
@article{schott_test_2007,
	title = {A test for the equality of covariance matrices when the dimension is large relative to the sample sizes},
	volume = {51},
	abstract = {A simple statistic is proposed for testing the equality of the covariance matrices of several multivariate normal populations. The asymptotic null distribution of this statistic, as both the sample sizes and the number of variables go to infinity, is shown to be normal. Consequently, this test can be used when the number of variables is not small relative to the sample sizes and, in particular, even when the number of variables exceeds the sample sizes. The finite sample size performance of the normal approximation for this method is evaluated in a simulation study.},
	number = {12},
	journal = {Computational Statistics \& Data Analysis},
	author = {Schott, James R.},
	month = aug,
	year = {2007},
	keywords = {Equal covariance matrices, high-dimensional data, Singular sample covariance matrix},
	pages = {6535--6542},
	file = {ScienceDirect Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/TSGJSBR4/Schott - 2007 - A test for the equality of covariance matrices whe.pdf:application/pdf}
}

@article{srivastava_tests_2014,
	title = {Tests for covariance matrices in high dimension with less sample size},
	volume = {130},
	abstract = {In this article, we propose tests for covariance matrices of high dimension with fewer observations than the dimension for a general class of distributions with positive definite covariance matrices. In the one-sample case, tests are proposed for sphericity and for testing the hypothesis that the covariance matrix Σ is an identity matrix, by providing an unbiased estimator of tr [ Σ 2 ] under the general model which requires no more computing time than the one available in the literature for a normal model. In the two-sample case, tests for the equality of two covariance matrices are given. The asymptotic distributions of proposed tests in the one-sample case are derived under the assumption that the sample size N = O ( p δ ) , 1 / 2 \&lt; δ \&lt; 1 , where p is the dimension of the random vector, and O ( p δ ) means that N / p goes to zero as N and p go to infinity. Similar assumptions are made in the two-sample case.},
	journal = {Journal of Multivariate Analysis},
	author = {Srivastava, Muni S. and Yanagihara, Hirokazu and Kubokawa, Tatsuya},
	month = sep,
	year = {2014},
	keywords = {asymptotic distributions, Covariance matrix, High dimension, Non-normal model, Sample size smaller than dimension, Test statistics},
	pages = {289--309},
	file = {ScienceDirect Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/V5DBSVR8/Srivastava et al. - 2014 - Tests for covariance matrices in high dimension wi.pdf:application/pdf}
}

@article{li_hypothesis_2014,
	title = {Hypothesis testing for high-dimensional covariance matrices},
	volume = {128},
	abstract = {This paper discusses the problem of testing for high-dimensional covariance matrices. Tests for an identity matrix and for the equality of two covariance matrices are considered when the data dimension and the sample size are both large. Most importantly, the dimension can be much larger than the sample size. The proposed test statistics are built upon the Stieltjes transform of the spectral distribution of the sample covariance matrix. We prove that the proposed statistics are asymptotically chi-square distributed under the null hypotheses, and normally distributed under the alternative hypotheses. Simulation results show that for finite dimension and sample size the proposed tests outperform some existing methods in various cases.},
	journal = {Journal of Multivariate Analysis},
	author = {Li, Weiming and Qin, Yingli},
	month = jul,
	year = {2014},
	keywords = {Covariance matrix, Empirical spectral distribution, High-dimensional, Hypothesis testing, Stieltjes transform},
	pages = {108--119},
	file = {ScienceDirect Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/QMGX7CXJ/Li and Qin - 2014 - Hypothesis testing for high-dimensional covariance.pdf:application/pdf}
}

@article{srivastava_testing_2010,
	title = {Testing the equality of several covariance matrices with fewer observations than the dimension},
	volume = {101},
	abstract = {For normally distributed data from the k populations with m × m covariance matrices Σ 1 , … , Σ k , we test the hypothesis H : Σ 1 = ⋯ = Σ k vs the alternative A ≠ H when the number of observations N i , i = 1 , … , k from each population are less than or equal to the dimension m , N i ≤ m , i = 1 , … , k . Two tests are proposed and compared with two other tests proposed in the literature. These tests, however, do not require that N i ≤ m , and thus can be used in all situations, including when the likelihood ratio test is available. The asymptotic distributions of the test statistics are given, and the power compared by simulations with other test statistics proposed in the literature. The proposed tests perform well and better in several cases than the other two tests available in the literature.},
	number = {6},
	journal = {Journal of Multivariate Analysis},
	author = {Srivastava, Muni S. and Yanagihara, Hirokazu},
	month = jul,
	year = {2010},
	keywords = {Comparison of powers, Equality of several covariance matrices, Equality of two covariances, high-dimensional data, Normality, sample size smaller than the dimension},
	pages = {1319--1329},
	file = {ScienceDirect Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/DDQUZ5RW/Srivastava and Yanagihara - 2010 - Testing the equality of several covariance matrice.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/SQ3DHBJK/S0047259X09002413.html:text/html}
}

@article{ishii_asymptotic_2016,
	title = {Asymptotic properties of the first principal component and equality tests of covariance matrices in high-dimension, low-sample-size context},
	volume = {170},
	abstract = {A common feature of high-dimensional data is that the data dimension is high, however, the sample size is relatively low. We call such data HDLSS data. In this paper, we study asymptotic properties of the first principal component in the HDLSS context and apply them to equality tests of covariance matrices for high-dimensional data sets. We consider HDLSS asymptotic theories as the dimension grows for both the cases when the sample size is fixed and the sample size goes to infinity. We introduce an eigenvalue estimator by the noise-reduction methodology and provide asymptotic distributions of the largest eigenvalue in the HDLSS context. We construct a confidence interval of the first contribution ratio and give a one-sample test. We give asymptotic properties both for the first PC direction and PC score as well. We apply the findings to equality tests of two covariance matrices in the HDLSS context. We provide numerical results and discussions about the performances both on the estimates of the first PC and the equality tests of two covariance matrices.},
	journal = {Journal of Statistical Planning and Inference},
	author = {Ishii, Aki and Yata, Kazuyoshi and Aoshima, Makoto},
	month = mar,
	year = {2016},
	keywords = {Contribution ratio, Equality test of covariance matrices, HDLSS, Noise-reduction methodology, PCA},
	pages = {186--199},
	file = {ScienceDirect Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/W9843FB6/Ishii et al. - 2016 - Asymptotic properties of the first principal compo.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/ZNPCZZQV/S0378375815001913.html:text/html}
}

@article{chaipitak_test_2013,
	title = {A test for testing the equality of two covariance matrices for high-dimensional data},
	volume = {13},
	number = {2},
	journal = {Journal of Applied Sciences},
	author = {Chaipitak, Saowapha and Chongcharoen, Samruam},
	year = {2013},
	pages = {270--277},
	file = {[PDF] from docsdrive.com:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/Z6XNDZR5/Chaipitak and Chongcharoen - 2013 - A test for testing the equality of two covariance .pdf:application/pdf}
}

@article{ledoit_well-conditioned_2004,
	title = {A well-conditioned estimator for large-dimensional covariance matrices},
	volume = {88},
	abstract = {Many applied problems require a covariance matrix estimator that is not only invertible, but also well-conditioned (that is, inverting it does not amplify estimation error). For large-dimensional covariance matrices, the usual estimator—the sample covariance matrix—is typically not well-conditioned and may not even be invertible. This paper introduces an estimator that is both well-conditioned and more accurate than the sample covariance matrix asymptotically. This estimator is distribution-free and has a simple explicit formula that is easy to compute and interpret. It is the asymptotically optimal convex linear combination of the sample covariance matrix with the identity matrix. Optimality is meant with respect to a quadratic loss function, asymptotically as the number of observations and the number of variables go to infinity together. Extensive Monte Carlo confirm that the asymptotic results tend to hold well in finite sample.},
	number = {2},
	journal = {Journal of Multivariate Analysis},
	author = {Ledoit, Olivier and Wolf, Michael},
	month = feb,
	year = {2004},
	keywords = {Condition number, Covariance matrix estimation, Empirical Bayes, General asymptotics, Shrinkage},
	pages = {365--411},
	file = {ScienceDirect Snapshot:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/6NXGA54N/S0047259X03000964.html:text/html}
}

@article{schott_tests_2001,
	title = {Some tests for the equality of covariance matrices},
	volume = {94},
	abstract = {A Wald statistic, which is asymptotically equivalent to the likelihood ratio criterion, is obtained for the test of the equality of covariance matrices. A more general Wald statistic is constructed under the assumption of elliptical distributions, and the comparison of these two statistics sheds some light on the asymptotic performance of the likelihood ratio test. In particular, we find that the likelihood ratio test is liberal for nonnormal elliptical populations with positive kurtosis and conservative for nonnormal elliptical populations with negative kurtosis. Further, the likelihood ratio test cannot be adjusted by a scalar multiple so as to retain its asymptotic chi-squared distribution over the class of elliptical distributions. A Wald test, appropriate for more general populations, is also obtained.},
	number = {1},
	journal = {Journal of Statistical Planning and Inference},
	author = {Schott, James},
	month = mar,
	year = {2001},
	keywords = {Elliptical distribution, Kurtosis, Wald statistic},
	pages = {25--36},
	file = {ScienceDirect Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/8MA4UVVJ/R. Schott - 2001 - Some tests for the equality of covariance matrices.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/KBJ8TBCW/S0378375800002093.html:text/html}
}

@inproceedings{srivastava_testing_2007,
	address = {University of North Carolina at Greensboro, NC, USA},
	title = {Testing the equality of two covariance matrices and independence of two sub-vectors with fewer observations than the dimension.},
	booktitle = {International {Conference} on {Advances} in {Interdisciplinary} {Stistics} and {Combinatorics}},
	author = {Srivastava, M. S},
	month = oct,
	year = {2007}
}

@article{srivastava_singular_2003,
	title = {Singular {Wishart} and {Multivariate} {Beta} {Distributions}},
	volume = {31},
	abstract = {In this article, we consider the case when the number of observations n is less than the dimension p of the random vectors which are assumed to be independent and identically distributed as normal with nonsingular covariance matrix. The central and noncentral distributions of the singular Wishart matrix S = XX′, where X is the p × n matrix of observations are derived with respect to Lebesgue measure. Properties of this distribution are given. When the covariance matrix is singular, pseudo singular Wishart distribution is also derived. The result is extended to any distribution of the type f(XX′) for the central case. Singular multivariate beta distributions with respect to Lebesgue measure are also given.},
	number = {5},
	journal = {The Annals of Statistics},
	author = {Srivastava, M. S.},
	year = {2003},
	pages = {1537--1560}
}

@book{fujikoshi_multivariate_2011,
	title = {Multivariate {Statistics}: {High}-{Dimensional} and {Large}-{Sample} {Approximations}},
	isbn = {978-0-470-53986-6},
	abstract = {A comprehensive examination of high-dimensional analysis of multivariate methods and their real-world applications Multivariate Statistics: High-Dimensional and Large-Sample Approximations is the first book of its kind to explore how classical multivariate methods can be revised and used in place of conventional statistical tools. Written by prominent researchers in the field, the book focuses on high-dimensional and large-scale approximations and details the many basic multivariate methods used to achieve high levels of accuracy. The authors begin with a fundamental presentation of the basic tools and exact distributional results of multivariate statistics, and, in addition, the derivations of most distributional results are provided. Statistical methods for high-dimensional data, such as curve data, spectra, images, and DNA microarrays, are discussed. Bootstrap approximations from a methodological point of view, theoretical accuracies in MANOVA tests, and model selection criteria are also presented. Subsequent chapters feature additional topical coverage including:  High-dimensional approximations of various statistics High-dimensional statistical methods Approximations with computable error bound Selection of variables based on model selection approach Statistics with error bounds and their appearance in discriminant analysis, growth curve models, generalized linear models, profile analysis, and multiple comparison  Each chapter provides real-world applications and thorough analyses of the real data. In addition, approximation formulas found throughout the book are a useful tool for both practical and theoretical statisticians, and basic results on exact distributions in multivariate analysis are included in a comprehensive, yet accessible, format. Multivariate Statistics is an excellent book for courses on probability theory in statistics at the graduate level. It is also an essential reference for both practical and theoretical statisticians who are interested in multivariate analysis and who would benefit from learning the applications of analytical probabilistic methods in statistics.},
	publisher = {John Wiley \& Sons},
	author = {Fujikoshi, Yasunori and Ulyanov, Vladimir V. and Shimizu, Ryoichi},
	month = aug,
	year = {2011},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{johnson_applied_2007,
	title = {Applied {Multivariate} {Statistical} {Analysis}},
	isbn = {978-0-13-187715-3},
	abstract = {This market leader offers a readable introduction to the statistical analysis of multivariate observations. Gives readers the knowledge necessary to make proper interpretations and select appropriate techniques for analyzing multivariate data. Starts with a formulation of the population models, delineates the corresponding sample results, and liberally illustrates everything with examples.  Offers an abundance of examples and exercises based on real data.  Appropriate for experimental scientists in a variety of disciplines.},
	publisher = {Pearson Prentice Hall},
	author = {Johnson, Richard Arnold and Wichern, Dean W.},
	year = {2007},
	keywords = {Mathematics / Probability \& Statistics / Multivariate Analysis}
}

@article{odom_regularized_2016,
	title = {Regularized {Linear} {Dimension} {Reduction} for the {Sample} {Quadratic} {Classifier}},
	journal = {Unpublished Manuscript},
	author = {Odom, Gabriel J and Young, Phil D. and Ramey, John A and Young, Dean M.},
	year = {2016},
	note = {00000}
}

@article{peters_characterizations_1978,
	title = {Characterizations of {Linear} {Sufficient} {Statistics}},
	volume = {40},
	issn = {0581-572X},
	url = {http://www.jstor.org/stable/25050156},
	abstract = {We develop necessary and sufficient conditions that a surjective bounded linear operator T from a linear space X to a linear space Y be a sufficient statistic for a dominated family of probability measures defined on the Borel sets of X. We give applications of these results that characterize linear sufficient statistics for families of the exponential type, including as special cases the Wishart and multivariate normal distributions.},
	number = {3},
	urldate = {2017-04-02},
	journal = {Sankhyā: The Indian Journal of Statistics, Series A (1961-2002)},
	author = {Peters, B. Charles and Redner, Richard and Decell, Henry P.},
	year = {1978},
	note = {00017},
	pages = {303--309}
}

@article{tubbs_linear_1982,
	title = {Linear dimension reduction and {Bayes} classification with unknown population parameters},
	volume = {15},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/0031320382900681},
	doi = {10.1016/0031-3203(82)90068-1},
	abstract = {Odell and Decell, Odell and Coberly gave necessary and sufficient conditions for the smallest dimension compression matrix B such that the Bayes classification regions are preserved. That is, they developed an explicit expression of a compression matrix B such that the Bayes classification assignment are the same for both the original space x and the compressed space Bx. Odell indicated that whenever the population parameters are unknown, then the dimension of Bx is the same as x with probability one. Furthermore, Odell posed the problem of finding a lower dimension q {\textless} p which in some sense best fits the range space generated by the matrix M. The purpose of this paper is to discuss this problem and provide a partial solution.},
	number = {3},
	urldate = {2017-04-02},
	journal = {Pattern Recognition},
	author = {Tubbs, J. D. and Coberly, W. A. and Young, D. M.},
	month = jan,
	year = {1982},
	note = {00039},
	keywords = {Bayes classification procedure, Dimension reduction, Feature selection, Probability of misclassification, Projection operator, Singular value decomposition},
	pages = {167--172},
	file = {ScienceDirect Snapshot:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/XAFZXKNB/0031320382900681.html:text/html}
}

@article{ounpraseuth_linear_2015,
	title = {Linear {Dimension} {Reduction} for {Multiple} {Heteroscedastic} {Multivariate} {Normal} {Populations}},
	volume = {05},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	url = {http://www.scirp.org/journal/PaperInformation.aspx?PaperID=57369&#abstract},
	doi = {10.4236/ojs.2015.54033},
	abstract = {For the case where all multivariate normal parameters are known, we derive a new linear dimension reduction (LDR) method to determine a low-dimensional subspace that preserves or nearly preserves the original feature-space separation of the individual populations and the Bayes probability of misclassification. We also give necessary and sufficient conditions which provide the smallest reduced dimension that essentially retains the Bayes probability of misclassification from the original full-dimensional space in the reduced space. Moreover, our new LDR procedure requires no computationally expensive optimization procedure. Finally, for the case where parameters are unknown, we devise a LDR method based on our new theorem and compare our LDR method with three competing LDR methods using Monte Carlo simulations and a parametric bootstrap based on real data.},
	language = {en},
	number = {04},
	urldate = {2017-04-02},
	journal = {Open Journal of Statistics},
	author = {Ounpraseuth, Songthip T. and Young, Phil D. and Zyl, Johanna S. van and Nelson, Tyler W. and Young, Dean M.},
	month = may,
	year = {2015},
	pages = {311},
	file = {Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/T82NGUMB/Ounpraseuth et al. - 2015 - Linear Dimension Reduction for Multiple Heterosced.pdf:application/pdf;Snapshot:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/7J4ZF9P5/PaperInformation.html:text/html}
}

@article{wickham_layered_2010,
	title = {A {Layered} {Grammar} of {Graphics}},
	volume = {19},
	abstract = {A grammar of graphics is a tool that enables us to concisely describe the components of a graphic. Such a grammar allows us to move beyond named graphics (e.g., the “scatterplot”) and gain insight into the deep structure that underlies statistical graphics. This article builds on Wilkinson, Anand, and Grossman (2005), describing extensions and refinements developed while building an open source implementation of the grammar of graphics for R, ggplot2. The topics in this article include an introduction to the grammar by working through the process of creating a plot, and discussing the components that we need. The grammar is then presented formally and compared to Wilkinson’s grammar, highlighting the hierarchy of defaults, and the implications of embedding a graphical grammar into a programming language. The power of the grammar is illustrated with a selection of examples that explore different components and their interactions, in more detail. The article concludes by discussing some perceptual issues, and thinking about how we can build on the grammar to learn how to create graphical “poems.” Supplemental materials are available online.},
	number = {1},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Wickham, Hadley},
	month = jan,
	year = {2010},
	keywords = {Grammar of graphics, Statistical graphics},
	pages = {3--28},
	file = {Full Text PDF:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/CN247WM5/Wickham - 2010 - A Layered Grammar of Graphics.pdf:application/pdf;Snapshot:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/H6MGG2RG/jcgs.2009.html:text/html}
}

@book{wilkinson_grammar_2006,
	title = {The {Grammar} of {Graphics}},
	isbn = {978-0-387-28695-2},
	abstract = {Preface to First Edition Before writing the graphics for SYSTAT in the 1980’s, I began by teaching a seminar in statistical graphics and collecting as many different quantitative graphics as I could find. I was determined to produce a package that could draw every statistical graphic I had ever seen. The structure of the program was a collection of procedures named after the basic graph types they p- duced. The graphics code was roughly one and a half megabytes in size. In the early 1990’s, I redesigned the SYSTAT graphics package using - ject-based technology. I intended to produce a more comprehensive and - namic package. I accomplished this by embedding graphical elements in a tree structure. Rendering graphics was done by walking the tree and editing worked by adding and deleting nodes. The code size fell to under a megabyte. In the late 1990’s, I collaborated with Dan Rope at the Bureau of Labor Statistics and Dan Carr at George Mason University to produce a graphics p- duction library called GPL, this time in Java. Our goal was to develop graphics components. This book was nourished by that project. So far, the GPL code size is under half a megabyte.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Wilkinson, Leland},
	month = jan,
	year = {2006},
	note = {Google-Books-ID: NRyGnjeNKJIC},
	keywords = {Computers / Computer Vision \& Pattern Recognition, Computers / Mathematical \& Statistical Software, Mathematics / Combinatorics, Mathematics / Graphic Methods, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@misc{noauthor_split-apply-combine_nodate,
	title = {The {Split}-apply-combine {Strategy} for {Data} {Analysis}. - {Google} {Scholar}},
	file = {The Split-apply-combine Strategy for Data Analysis. - Google Scholar:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/C76FT696/scholar.html:text/html}
}

@misc{noauthor_tidy_nodate,
	title = {Tidy data},
	file = {Tidy data:/Users/ben_barnard/Library/Application Support/Zotero/Profiles/sggcd9aj.default/zotero/storage/59CRMMBQ/tidy-data.html:text/html}
}